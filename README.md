![Steam logo](./Assets/logo.jpg)


# <p align="center">Proyecto Individual NÂ°1</p>

### Ãndice
**Parte I: Sobre el Proyecto**
- Proceso detrÃ¡s del proyecto

**Parte II: Estructura del Repositorio Github**
- Desglose detallado de la organizaciÃ³n de archivos y carpetas

**Parte III: Contacto**
- InformaciÃ³n para ponerse en contacto

---

### IntroducciÃ³n 

Este proyecto forma parte de la etapa de Labs para la carrera de Data Science de [Henry](https://www.soyhenry.com/). El proyecto utiliza data real de una plataforma multinacional de videojuegos llamada Steam y se desarrolla bajo un rol de **Data Scientist** para solucionar un problema de negocio.  

### Objetivo
El objetivo principal ðŸŽ¯ es crear un sistema de recomendaciÃ³n de videojuegos para usuarios realizando un flujo de trabajo completo de MLOps para tener un Minimum Viable Product (MVP) al finalizar el proyecto. 

#### Objetivos EspecÃ­ficos
* Realizar la ingenierÃ­a de datos de los archivos fuente (ETL), incluye la ingesta de datos, el tratamiento (Feature Engineering) y su disponibilizaciÃ³n.
* CreaciÃ³n de una API y el deployment de funciones como respuesta a preguntas de negocio.
* PresentaciÃ³n del AnÃ¡lisis exploratorio de los datos (Exploratory Data Analysis - EDA).
* Desarrollo del sistema de recomendaciÃ³n.

![Processo](./Assets/process.png)


--- 

Este proyecto consta de tres fases: `IngenierÃ­a de datos`, `AnÃ¡lisis exploratorio de los datos`, `Modelo de aprendizaje automÃ¡tico`.

ðŸ” Se recomienda leer los notebooks a los que se hace referencia a lo largo de este archivo, contienen informaciÃ³n detallada de cada anÃ¡lisis.

---
### 1. IngenierÃ­a de datos
`Data Engineering`: Para el proyecto se brinda 3 archivos JSON con datos anidados: australian_user_reviews , australian_user_items y output_steam_games. AdemÃ¡s, un diccionario de datos con informaciÃ³n de algunas variables de los datasets.

* [Carpeta Datasets + Diccionario](https://drive.google.com/drive/folders/1PvMb8F0veZYFmmcZytfVBNvmfzi6Rwl9?usp=drive_link)


### 1.1 ETL
Como primer paso se realiza el ETL de cada uno de los archivos proporcionados. El objetivo es preparar y disponibilizar los datos para su posterior anÃ¡lisis. Incluye la extracciÃ³n de datos, tratamiento y carga.

### ExtracciÃ³n, Transformaciones y Carga

Se trabaja el ETL de los tres datasets en tres distintos **notebooks**. Los tres datasets se trabajan como dataframes los cuales se exploran, se realiza el tratamiento de nulos, duplicados, outliers y se utilizan tÃ©cnicas de imputaciÃ³n de datos segÃºn el caso. Asimismo, con el objetivo de preparar los datos para el desarrollo de funciones para los endpoint de las consultas a desarrollar en la API, se considera solo columnas con informaciÃ³n necesaria.

| Dataset | DescripciÃ³n | Output|
| ------------ | ------------ |--------|
| australian_user_review   | Contiene informaciÃ³n sobre las reseÃ±as de los juegos hecho por los usuarios de la plataforma STEAM. La informaciÃ³n que nos muestra es: user_id, user_url, reviews. | user_reviews_final.csv| Contiene informaciÃ³n sobre los items (o juegos) jugados por los usuarios de la plataforma STEAM. La informaciÃ³n que nos muestra es: user_id, user_url, y items.
| australian_user_items    | Contiene informaciÃ³n sobre items. La informaciÃ³n que nos muestra es user_id, items_count_steam_id, user_url, items. Cada 'items' de un usuario es una lista de diccionarios en formato JSON. Cada elemento de la lista contiene pares clave-valor (como "item_id", "item_name", "playtime_forever" y "playtime_2weeks").    |user_items_final.csv|
| output_steam_games   | Contiene el detalle sobre los juegos de la plataforma STEAM. La informaciÃ³n que nos muestra es: 'publisher', 'genres', 'app_name', 'title', 'url', 'release_date', 'tags', 'reviews_url', 'specs', 'price', 'early_access', 'id' y 'developer'. Donde item_id es Ãºnico.  |steam_games_final.csv


**Feature Engineering**: Se realiza un anÃ¡lisis de sentimiento con NLP en el dataset australian_user_review en el cual se clasifican las reseÃ±as con los valores de 0: si es malo, 1: si es neutral y 2: si es positivo y se almacena en una nueva variable `sentiment_analysis`.


Nombre de los Notebooks del ETL:
* ETL_User_Reviews
* ETL_User_Items
* ETL_output_steam_games


Los outputs del ETL se encuentran en:
* [Carpeta Output ETL](https://drive.google.com/drive/folders/1ShuNW4ACMe9F5oz7omP5UigJ37ivj3Ec?usp=drive_link)



### 1.2 API

### CreaciÃ³n de funciones y desarrollo de la API
En esta parte se crean las cinco funciones para los endpoints que se consumirÃ¡n en la API. 

Previamente realicÃ© un preprocesamiento de los datasets que consistiÃ³ en formar datasets con solamente la informaciÃ³n que la funciÃ³n necesita. Esto se hizo con la finalidad de optimizar la ejecuciÃ³n de la API. 

Luego, creÃ© las funciones que se implentan en los endpoints los cuales responden a preguntas relacionadas al anÃ¡lisis de datos de los juegos. Desde identificar el aÃ±o con mÃ¡s horas jugadas para un gÃ©nero especÃ­fico hasta proporcionar recomendaciones y evaluaciones de usuarios, estos endpoints cubren aspectos clave de la experiencia de juego y permiten una mejor comprensiÃ³n del comportamiento de los usuarios y sus preferencias. Son las siguientes:

âž” Endpoint 1 (`PlayTimeGenre`): Devuelve aÃ±o con mas horas jugadas para un gÃ©nero dado.

âž” Endpoint 2 (`UserForGenre`): Devuelve el usuario que acumula mÃ¡s horas jugadas para el gÃ©nero dado y una lista de la acumulaciÃ³n de horas jugadas por aÃ±o.

âž” Endpoint 3 (`UsersRecommend`): Devuelve el top 3 de juegos mÃ¡s recomendados por usuarios para el aÃ±o dado.

âž” Endpoint 4 (`UsersWorstDeveloper`): Devuelve el top 3 de desarrolladoras con juegos MENOS recomendados por usuarios para el aÃ±o dado

âž” Endpoint 5 (`sentiment_analysis`): SegÃºn la empresa desarrolladora, se devuelve un diccionario con el nombre de la desarrolladora como llave y una lista con la cantidad total de registros de reseÃ±as de usuarios que se encuentren categorizados con un anÃ¡lisis de sentimiento como valor.

El desarrollo de la API se hizo localmente con FastAPI para lo cual se creo un entorno virtual ("proyecto01_venv").

Nombre del Notebook previo a la creaciÃ³n de funciones:
* Previo_Funcion_sistema_recomendacion

Los inputs de las funciones se encuentran en:
* [Carpeta Input funciones](https://drive.google.com/drive/folders/1jPyN2m9EQJGm3RQzZoxpBWNvXzdJUwz4?usp=drive_link)

Archivo Notebook con definiciÃ³n de funciones:
* Funciones_endpoints

Archivos requeridos para la API:
* functions.py
* main.py

---

### 2. AnÃ¡lisis exploratorio de Datos 
`EDA`: Algunos de los aspectos clave que se explorÃ³ incluyen anÃ¡lisis descriptivo, identificaciÃ³n de valores atÃ­picos (outliers o anomalÃ­as), visualizaciones de distribuciones para identificar tendencias, patrones, posibles correlaciones entre factores, entre otros.

*Nota: En este punto se hace foco a las distribuciones de las variables y las relaciones entre ellas, toda la limpieza (nulos, duplicados y faltantes) ya se desarrollÃ³ en la secciÃ³n del ETL.

### 3. Modelo de aprendizaje automÃ¡tico

Sistema de RecomendaciÃ³n Ã­tem-Ã­tem (`recomendacion_juego`): 
Se implementÃ³ un sistema que recomienda juegos similares a un item. Previamente se trabajÃ³ un notebook (Previo_Funcion_sistema_recomendacion.ipynb) donde se preparÃ³ un dataset que contiene solo informaciÃ³n relevante para crear el sistema. En este notebook se utilizÃ³ la similitud de cosenos utilizando vectores sobre l variables 'genres' y su previo traspase a variables dummies. Con cosine_similarity se creÃ³ la matriz de similitud de cosenos. Este mÃ©todo fue clave para determinar los cinco juegos recomendados similares al ingresado.


### 4. Deployment de la API
Se verificÃ³ la funcionalidad de los endpoints localmente y luego se deployÃ³ en RENDER para ser consumida desde la web . 

ðŸš€ Link a la API deployada con Render: [LINK](https://proyecto-individual01-mlops-jimenez-v1.onrender.com)

### 5. Video Explicativo
La grabaciÃ³n contiene la **explicaciÃ³n** del proyecto,  una muestra la API deployada, todos los endpoints **correctamente** funcionando en Render, next steps y **recomendaciones** al proyecto.[LINK](https://drive.google.com/file/d/18tQ-hwa3Lbui2vWvT2FrjM8v_wXEFw1o/view?usp=sharing)


---
### Estructura del Repositorio
El reporitorio de divide de la siguiente forma:

> Carpeta Datasets: Contiene los 3 archivos iniciales .json y una carpeta de los archivos output del ETL.

> Carpeta Notebooks: Todos los notebooks (3 archivos del ETL, 1 del previo a las funciones, 1 previo al sistema de recomendaciÃ³n item-item, 1 previo al sistema de recomendaciÃ³n usuario-item, 1 del EDA y 1 de las funciones para los endpoints).

> Otros archivos: Archivos requeridos para el deployment en Render.

---
### Contacto
Autor: Anabel Jimenez

Enlaces para ponerse en contacto:
  - Correo ElectrÃ³nico: [anabeljimenezh19@gmail.com](mailto:tu@email.com)
  - LinkedIn: [@AnabelJimenez](https://twitter.com/NuestraCuenta)
--- 
<img src="./Assets/logohenry.jpg" alt="Steam logo" align="left" width="100"/> 


